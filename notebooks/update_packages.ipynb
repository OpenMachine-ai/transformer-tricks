{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lOsSebCDGVTh"
      },
      "outputs": [],
      "source": [
        "# This colab helps you to fix python package issues:\n",
        "#   - The huggingface (HF) packages are updated very often\n",
        "#   - We want the transformer-tricks package to work with the (almost) latest\n",
        "#     HF packages\n",
        "#   - We only need 3 HF packages: transformers, accelerate, datasets\n",
        "#   - These 3 HF packages will load many other HF packages (such as safetensors,\n",
        "#     hub), numpy and torch\n",
        "\n",
        "# remove all pip packages, except for pip, dateutil, certifi, etc.\n",
        "!pip list --format=freeze | grep -v -E \"pip|dateutil|certifi|psutil|_distutils_hack|pkg_resources\" | xargs pip uninstall -y --quiet\n",
        "\n",
        "# above takes about 6 minutes !!!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install latest versions of the 3 HF packages\n",
        "!pip install transformers --quiet\n",
        "!pip install accelerate --quiet\n",
        "!pip install datasets --quiet\n",
        "\n",
        "!pip list | grep -E \"transformers|accelerate|datasets\"\n",
        "!pip list | grep -E \"torch|numpy|safetensors|huggingface\"\n",
        "!python -V"
      ],
      "metadata": {
        "id": "kWz9vRphZL2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download files transformer_tricks.py and flashNorm_test.py and test if it\n",
        "# works with the latest version of the HF packages\n",
        "!wget -q https://raw.githubusercontent.com/OpenMachine-ai/transformer-tricks/refs/heads/main/transformer_tricks.py\n",
        "!wget -q https://raw.githubusercontent.com/OpenMachine-ai/transformer-tricks/refs/heads/main/flashNorm_example.py\n",
        "!wget -q https://raw.githubusercontent.com/OpenMachine-ai/transformer-tricks/refs/heads/main/flashNorm_modeling_llama.py\n",
        "\n",
        "!python flashNorm_example.py"
      ],
      "metadata": {
        "id": "FCh28_1fauTX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}