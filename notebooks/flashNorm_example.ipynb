{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ad1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example converts SmolLM-135M to FlashNorm and measures\n",
    "# its perplexity before and after the conversion.\n",
    "#\n",
    "# Usage: python3 flashNorm_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09625c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------\n",
    "# Example 1\n",
    "#-------------------------------------------------------------------------------------\n",
    "\n",
    "%pip install --quiet transformer_tricks\n",
    "import transformer_tricks as tt\n",
    "\n",
    "tt.quiet_hf()  # calm down HuggingFace\n",
    "\n",
    "# convert model and store the new model in ./SmolLM-135M_flashNorm_test\n",
    "tt.flashify_repo('HuggingFaceTB/SmolLM-135M')\n",
    "\n",
    "# run example inference of original and modified model\n",
    "tt.hello_world('HuggingFaceTB/SmolLM-135M')\n",
    "tt.hello_world('./SmolLM-135M_flashNorm_test')\n",
    "\n",
    "# measure perplexity of original and modified model\n",
    "tt.perplexity('HuggingFaceTB/SmolLM-135M', speedup=16)\n",
    "tt.perplexity('./SmolLM-135M_flashNorm_test', speedup=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebec3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------\n",
    "# Example 2\n",
    "#-------------------------------------------------------------------------------------\n",
    "\n",
    "!wget https://raw.githubusercontent.com/OpenMachine-ai/transformer-tricks/refs/heads/main/python/flashNorm_modeling_llama.py\n",
    "\n",
    "tt.quiet_hf()  # calm down HuggingFace\n",
    "\n",
    "# convert model and store the new model in ./SmolLM-135M_flashNorm\n",
    "tt.flashify_repo('HuggingFaceTB/SmolLM-135M')\n",
    "\n",
    "# run example inference of original and modified model\n",
    "tt.hello_world('HuggingFaceTB/SmolLM-135M')\n",
    "tt.hello_world('./SmolLM-135M_flashNorm', arch='LlamaFlashNorm')\n",
    "\n",
    "# measure perplexity of original and modified model\n",
    "tt.perplexity('HuggingFaceTB/SmolLM-135M', speedup=16)\n",
    "tt.perplexity('./SmolLM-135M_flashNorm', speedup=16, arch='LlamaFlashNorm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bce35d",
   "metadata": {},
   "source": [
    "Whenever you change this file, make sure to regenerate the jupyter notebook as follows:\n",
    "  `jupytext flashNorm_example.py -o ../notebooks/flashNorm_example.ipynb`"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
