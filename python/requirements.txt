transformers==4.41.2
datasets==2.19.2
transformer-tricks>=0.1.14
accelerate>=0.9.0
torch>=2.4.1
tqdm>=4.64.1
jupytext>=1.16.4
autopep8>=2.3.1

# other transformer versions to try
# 4.44.2  -- TODO: fix the warnings
# 4.42.4  -- TODO: fix the warnings
# 4.41.2
# 4.40.2
# 4.39.3
# 4.38.2
#
# pip list  # see all versions
#
# Phi-3 needs flash-attn, but this requires CUDA
# flash-attn==2.5.8
