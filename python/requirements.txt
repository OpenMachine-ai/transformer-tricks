transformers==4.45.2
datasets==2.19.2
transformer-tricks>=0.1.16
accelerate>=0.9.0
torch>=2.4.1
tqdm>=4.64.1
jupytext>=1.16.4
autopep8>=2.3.1

# pip list  # see all versions
#
# Phi-3 needs flash-attn, but this requires CUDA
# flash-attn==2.5.8
